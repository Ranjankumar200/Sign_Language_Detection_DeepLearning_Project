**Introduction**

This project focuses on detecting hand gestures for sign language interpretation using a Convolutional Neural Network (CNN).
The model is trained on a custom hand gesture dataset and built using TensorFlow/Keras.
It can classify multiple static gestures such as ONE, TWO, THREE... or custom signs for real-time or batch predictions. 

Communication is one of the most important parts of our daily lives. 
For people who are deaf or hard of hearing, sign language is a powerful way to express themselves. 
However, not everyone understands sign language, which can lead to communication barriers in everyday 
situations like schools, hospitals, or public places.
With the help of technology, especially computer vision and deep learning, we now have the ability 
to teach machines to understand visual information like hand gestures. This project, 
Sign Language Detection, focuses on recognizing hand gestures used in sign language. 
The goal is to take a small step toward bridging the gap between sign language users and non-signers, 
making communication more inclusive and accessible for everyone.

step1 - clone this repositor in your local machine to clone use below command

   git clone https://github.com/Sachin2501/Sign_Language_Detection_DeepLearning_Project.git
   
Step2 - Now you have to install all requiremets/libraries

   pip install requirements.txt
   
  
